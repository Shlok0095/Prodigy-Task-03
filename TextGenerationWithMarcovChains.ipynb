{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koAcuHotDQnp",
        "outputId": "f0b90e10-25ce-4e47-eae6-b8cc81223716"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Kaggle JSON file"
      ],
      "metadata": {
        "id": "bA_GzmEAGHfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of kaggle.json file use ! before writing the funtion\n",
        "!mkdir  -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "iOUl8fRsDQp-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset directly through Kaggle"
      ],
      "metadata": {
        "id": "kfMgA8xrGLl5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az7q48BqC6Ft",
        "outputId": "4ca2924c-ba4e-430e-d2df-095f209ce104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/idevji1/sherlock-holmes-stories\n",
            "License(s): CC0-1.0\n",
            "Downloading sherlock-holmes-stories.zip to /content\n",
            " 91% 9.00M/9.93M [00:00<00:00, 25.6MB/s]\n",
            "100% 9.93M/9.93M [00:00<00:00, 28.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d idevji1/sherlock-holmes-stories"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzipping Dataset"
      ],
      "metadata": {
        "id": "UJKzpwzvGZfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "unzipped_text_data = \"/content/sherlock-holmes-stories.zip\"\n",
        "with ZipFile(unzipped_text_data,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTlrdhFUDQsc",
        "outputId": "76e88fb2-13e3-4d7d-9351-55b479282926"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dependencies"
      ],
      "metadata": {
        "id": "Wfwtg__FGcrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "import nltk"
      ],
      "metadata": {
        "id": "_e1o360BEC_V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text pre-processing"
      ],
      "metadata": {
        "id": "hpRbnDIvGi2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story_path = \"/content/sherlock/\"\n",
        "\n",
        "def read_all_stories(story_path):\n",
        "    txt = []\n",
        "    for _, _, files in os.walk(story_path):\n",
        "        for file in files:\n",
        "            with open(os.path.join(story_path, file)) as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line == '-----------': break\n",
        "                    if line != '': txt.append(line)\n",
        "    return txt\n",
        "\n",
        "stories = read_all_stories(story_path)\n",
        "print(\"number of lines =\", len(stories))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Q3cIT5GHwz",
        "outputId": "a3f8a85e-9398-468a-a07b-6c6d6b7892fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of lines = 431326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK_IRqkFkJwW",
        "outputId": "015f7b80-ef14-4806-e825-bab083eca442"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_txt(txt):\n",
        "  cleaned_txt = []\n",
        "  for line in txt:\n",
        "    line = line.lower()\n",
        "    line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "    tokens = word_tokenize(line)\n",
        "    words = [word for word in tokens if word.isalpha()]\n",
        "    cleaned_txt += words\n",
        "  return cleaned_txt\n",
        "\n",
        "cleaned_stories = clean_txt(stories)\n",
        "print(\"number of words = \", len(cleaned_stories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-bw_m-Gh_Bf",
        "outputId": "266e5fa6-2036-4506-d3eb-382a904d9a98"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words =  4675490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Markov Chain Algorithm or model from scratch"
      ],
      "metadata": {
        "id": "bzRYDShSGopG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "\n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "\n",
        "    return markov_model"
      ],
      "metadata": {
        "id": "Qz-R3sQRkBAA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = make_markov_model(cleaned_stories)"
      ],
      "metadata": {
        "id": "ojRnCj6AloX7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of states = \", len(markov_model.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aUrXC9tngyX",
        "outputId": "8a4964ae-b5ae-4a10-8572-1e427dad55a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states =  208801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All possible transitions from a state \\n\")\n",
        "print(markov_model['the game'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mxt9Hn1os0Y",
        "outputId": "443fb022-3aef-4a84-e52d-b963ce46e8d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All possible transitions from a state \n",
            "\n",
            "{'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'would have': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'in their': 0.036036036036036036, 'was whist': 0.036036036036036036, 'was up': 0.09009009009009009, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'is afoot': 0.036036036036036036, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'was afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703, 'your letter': 0.02702702702702703}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Word generating fn"
      ],
      "metadata": {
        "id": "U3VC6_fbG2wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story+=curr_state+\" \"\n",
        "    while n<limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "\n",
        "        curr_state = next_state[0]\n",
        "        story+=curr_state+\" \"\n",
        "        n+=1\n",
        "    return story"
      ],
      "metadata": {
        "id": "cpjtk4Sno8PM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_text(markov_model, start=\"dear holmes\", limit=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlFIjKRIp5Xb",
        "outputId": "f08459d5-4b6f-40f8-98ee-fd7f4f44bddb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  dear holmes he has not entirely a wasted one my wife had some inkling of his property into \n",
            "1.  dear holmes am i addressing dr watson i am all this dr barnicot is an enthusiastic admirer of \n",
            "2.  dear holmes and tell him his features were peaky and sallow and his little game what did she \n",
            "3.  dear holmes oh yes no doubt that you have brought you something fresh inspector macdonald had been staring \n",
            "4.  dear holmes what do you make of that room absolutely nothing the landlady drew an envelope and examining \n",
            "5.  dear holmes if i should return tingling with anger i do not know but once inside the door \n",
            "6.  dear holmes if i could get a divorce from my brother this morning in company with a smart \n",
            "7.  dear holmes it is the only person who is a serious case against the son of sir charles \n",
            "8.  dear holmes oh yes i sent it from the front room while the elder to whose mercy i \n",
            "9.  dear holmes what do you think a man at the morass and again on july there was a \n",
            "10.  dear holmes said i but the colonel answered only in the diogenes club for example i find that \n",
            "11.  dear holmes i thought that i might be others so dont make a saint of me but hes \n",
            "12.  dear holmes what do you think it would very quickly test the matter when looking up saw me \n",
            "13.  dear holmes it is an awful place and having first covered him over with bunsen burners and retorts \n",
            "14.  dear holmes that i have not got the head and laid a note upon a leaf from his \n",
            "15.  dear holmes what do you make him a decidedly nautical appearance and in guilt was the ground that \n",
            "16.  dear holmes i ejaculated precisely so but how did you not call me a pencil and that slip \n",
            "17.  dear holmes i have said that i should be guilty of a hand at anything i have found \n",
            "18.  dear holmes he has done for he was always the man of letters said he how did you \n",
            "19.  dear holmes oh yes sir i am your prisoner she said from where i lay i marked it \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_text(markov_model, start=\"my dear\", limit=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUJFhj9oFyHp",
        "outputId": "d57c2170-2012-49a2-f8d7-9b4ae1c9695e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  my dear watson said he laughing im an honest man though not marked under that name well you \n",
            "1.  my dear watson said she for three days last week he hurled him back mcginty released his hold \n",
            "2.  my dear holmes i fear there is some guilty secret which appeared from the steep roof there sprang \n",
            "3.  my dear fellow and i he had filled out his hand and a bundle of clothing comprising a \n",
            "4.  my dear watson that at two oclock yesterday afternoon a fortnight or so later i found myself it \n",
            "5.  my dear mr mac but how are we to give to the man that was more pleased than \n",
            "6.  my dear chap i had seen you say that no one not miss harrison sitting there in the \n",
            "7.  my dear watson was asking for your advice it is friday man your wife asked you jones i \n",
            "8.  my dear watson said he now let me talk about david that one word shall they have from \n",
            "9.  my dear fellow for a german very thin very wrinkled bent with age an opium pipe dangling down \n",
            "10.  my dear watson that the lady absolutely refused to marry him next year did you not investigate no \n",
            "11.  my dear boy children come said i then worked the lawn very carefully for a hundred yards behind \n",
            "12.  my dear girl it would break his noble heart holmes raised the hair upon its body what is \n",
            "13.  my dear dear son the seamen had hauled the aback during the last few days now and the \n",
            "14.  my dear watson yet another had the volume from the edge of the wood of the hills great \n",
            "15.  my dear fellow there is no doubt about the beetling forehead the eyelids and the shoulders tut these \n",
            "16.  my dear watson said he you will only come around at quarter to twelve this could only be \n",
            "17.  my dear watson without your perceiving the drift of my own stupidity in my heart that i take \n",
            "18.  my dear fellow pray come in like that before i saw frank here again but it was equally \n",
            "19.  my dear sir knowing the vindictive character of a woman you say mr white mason i wish to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_text(markov_model, start=\"i would\", limit=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc5j3DwwF5c4",
        "outputId": "fdc6c1fe-b5b2-4ea5-fbb1-5bed87044dec"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  i would have endured imprisonment ay even execution rather than in this there is laura lyons by representing \n",
            "1.  i would spend my life hiking round the neck of the excited spaniel he had risen from his \n",
            "2.  i would go away afterwards and each will supplement the efforts of the police are hurrying up the \n",
            "3.  i would say nothing to him yet that is precisely for that purpose youve got to the end \n",
            "4.  i would respond to such a plight before me its a fine lad a staunch lad nothing would \n",
            "5.  i would suggest for example that a presentation would be more trying to the rocks on the sea \n",
            "6.  i would suggest that mr cubitts body may now be found in the room with an energy and \n",
            "7.  i would not tell it if its any use in my resisting and that is what i would \n",
            "8.  i would be at st saviours near kings cross and we were going on within the last hours \n",
            "9.  i would part with them for as i say left these jewels to pay some accounts i was \n",
            "10.  i would have endured imprisonment ay even execution rather than of a strange woman who had one of \n",
            "11.  i would venture to smoke to pass the time and showed that my surmise as you do von \n",
            "12.  i would carry such things and came right away to you and your friend in trouble he asked \n",
            "13.  i would do it ill go upstairs and a few minutes the dear fellow no one save barney \n",
            "14.  i would always carry the case in point as it seemed to vary with every fresh question would \n",
            "15.  i would venture to say that he had left the office of the line of his head and \n",
            "16.  i would have given you the story holmes sat down again after rounding the isle of dogs the \n",
            "17.  i would really rather not well possibly so there are reasons why she should have joined us in \n",
            "18.  i would not have carried out and one who had lost his nerve i can understand his taking \n",
            "19.  i would go with it the moment that i saw something in his hand perhaps you have said \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_text(markov_model, start=\"come on\", limit=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOO3AfxHJS1U",
        "outputId": "2079bdd8-c811-4d02-f3f8-7106a4df16f6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  come on something later which will make england ring you will get food and so trace it to \n",
            "1.  come on mcmurdo and scanlan would put the powder above it and it is so lonely up there \n",
            "2.  come on suddenly in the middle of that prairie a fairly safe ground do we not perhaps you \n",
            "3.  come on my boy these were the main gate and share the watch with my punjaubees they were \n",
            "4.  come on he rushed into his pocket most likely never noticing that a corner and pointed up the \n",
            "5.  come on the line of his chair like an old black frock coat which with his own eyes \n",
            "6.  come on a visit indeed you seem to him that he would pass london bridge there is a \n",
            "7.  come on mcmurdo and scanlan strolled on with an ivory miniature and the artist takes in his own \n",
            "8.  come on watson we shall order you a completely new idea of the truth it was the work \n",
            "9.  come on a visit of a black villain and caught in a half gloom far away we could \n",
            "10.  come on he rushed at one time why whatever is emotional is opposed to that true cold reason \n",
            "11.  come on a good look at the papers before morning when john mason had many of the family \n",
            "12.  come on the nasty angular uncompromising bits which wont slip into their places i take it as a \n",
            "13.  come on watson we can but try as he walked over from the station i kept to the \n",
            "14.  come on to the winds if he was crawling mr holmes crawling he was a perfect longing for \n",
            "15.  come on he rushed down just after breakfast i heard a cry of surprise and dismay his face \n",
            "16.  come on to the steep descent to the crime his defence was reserved for you in your trial \n",
            "17.  come on important business and a stolid village policeman made up the shutters for fear of a relapse \n",
            "18.  come on suddenly in the middle of the veiled lodger when one saw the spot at which the \n",
            "19.  come on suddenly in the middle of it we were pursuing could there be in that sorry house \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(markov_model, start=\"the case\", limit=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvnFX76TF9N8",
        "outputId": "1ef1ea93-6303-4f98-8f62-1ce4138ab6b9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the case precisely so i ought to make up for me in my dreams look out of my scientific methods of the police no no my dear sir if you are to wait here a moment i feared so much as you will find the facts themselves have often been so slight an obstacle why then was he that mr evans there is no use you may have gone out of the wedding it missed him he spoke and he galloped several miles before i fainted when it felt the hand of the man that he has disappeared and although also he is not worth your while to me the letter ill tell you so i have had nothing to do with much less than two miles to the north of oporto the proceedings and if browner had occasion to raise it the box and the trees were standing out in vivid relief upon the skin which on consideration of some few words of congratulation and then sat downcast with my head there was a sharp tap at the door of the manor house in consultation with his hand on a weapon which will be of national importance of the matter until \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_zHneGUJP3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}